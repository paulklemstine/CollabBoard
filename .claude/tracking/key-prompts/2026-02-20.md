# Key Prompts — 2026-02-20

## [2026-02-20] — Full containment required for frame drop highlight
**Category**: feature
**Context**: When dragging components over a frame/group, the green highlight (accept indicator) appeared when only the center of the object was inside the frame. User wanted the green flag only when the entire object fits completely inside.
**The Prompt**: "when a component or multiselect group of components are dragged over a frame/group they must fit completely before getting a green flag"
**Why It Worked**: Clear, concise requirement specifying both the single-component and multiselect cases, making the scope of the change unambiguous.
**Prior Attempts That Failed**: N/A

## [2026-02-20] — Red/green tint on dragged items during frame containment
**Category**: feature
**Context**: When dragging items over a frame, only the frame border showed accept/reject state. User wanted the dragged items themselves to also show green/red tinting for clearer visual feedback.
**The Prompt**: "when items are being dropped into a frame or group and they don't fit, remember to display red as a rejection notice" + "tint the selected items green/red also"
**Why It Worked**: Two complementary requests that together defined the full UX: (1) restore red rejection indicator on frames, (2) also tint the dragged items. Required understanding the two-phase detection: center-point for hover detection, full containment for accept/reject.
**Prior Attempts That Failed**: Previous change made findContainingFrame require full containment, which eliminated the red reject state entirely since no frame was detected when items didn't fit.

## [2026-02-20] — Upgrade AI alignment tools + selection awareness
**Category**: feature
**Context**: AI alignment tool confused "align horizontally" (horizontal line = same Y) with center-horizontal (same X). Also, selection info was appended as text to the prompt but the AI had no dedicated tool or board-state awareness of selection.
**The Prompt**: "Rename center-horizontal/vertical to center-x/center-y, add disambiguation to system prompt, add getSelectedObjects tool, make getBoardState/searchObjects show sel:true for selected items, fix useAI stale closure bug"
**Why It Worked**: Attacked the problem from multiple angles: (1) clearer enum names remove semantic ambiguity, (2) explicit disambiguation section in system prompt teaches the model the mapping, (3) dedicated tool + sel:true flag give the AI structured access to selection state, (4) ref-based fix ensures the right selection reaches Firestore.
**Prior Attempts That Failed**: N/A — first implementation based on plan.

## [2026-02-20] — Complete UI overhaul: unified violet design system
**Category**: feature
**Context**: The app had 12+ color families fighting (rainbow gradients, pink, green, indigo, cyan, orange, etc.) making it look inconsistent and unprofessional. User asked for a complete UI overhaul.
**The Prompt**: "can you brainstorm a complete UI overhaul? it looks like crap right now, with weird colors, etc. Give our whole app a consistent look and feel" → then "go ahead, implement it"
**Why It Worked**: Direct, honest feedback about the visual problem. The brainstorm-then-implement approach let us audit all colors across the codebase first, identify 12 distinct color families, then systematically replace them with a single violet-primary palette.
**Prior Attempts That Failed**: N/A — first attempt, systematic approach across 16 files touching every UI surface.

## [2026-02-20] — Persistent per-user undo/redo history
**Category**: feature
**Context**: Undo/redo history was purely in-memory (useRef stacks). Refreshing the page lost all undo history. Needed persistence scoped per-user so users can only undo their own changes.
**The Prompt**: "Implement persistent per-user undo/redo history" with a detailed plan specifying Firestore storage at boards/{boardId}/undoHistory/{userId}, debounced writes, trimToFit for size limits, and security rules.
**Why It Worked**: Well-structured plan with clear file-level responsibilities: new service for Firestore I/O with trimToFit, hook modification for load-on-mount + debounced-save + flush-on-unmount, minimal App.tsx change (just pass userId), and security rules scoping access per-user.
**Prior Attempts That Failed**: N/A — plan-first implementation.

## [2026-02-20] — Aura Polish: micro-animations + selection overhaul
**Category**: feature
**Context**: Flow Space needed playful micro-interactions for polish — parallax background, drop bounce animations, selection pop, marching ants on multi-select, violet glow replacing per-object dashed borders in multi-select, presence toasts, and confetti on AI completion.
**The Prompt**: Detailed 7-part plan covering parallax dots, drop bounce (ElasticEaseOut), selection pop (1.03x scale), marching ants (Konva.Animation dashOffset), multi-select glow (suppress dashed border, add violet shadow), presence join/leave toasts, and confetti burst on AI completion.
**Why It Worked**: Plan organized changes by visual effect rather than by file, making each feature self-contained. Specifying exact easing curves, durations, and color values (#8b5cf6 violet) eliminated ambiguity. The multi-select glow approach (shadowColor conditional on `selectionBox` prop) reused existing architecture cleanly.
**Prior Attempts That Failed**: N/A — plan-first implementation across 10 files.

## [2026-02-20] — Update AI tooling to know about all board features
**Category**: feature
**Context**: The AI agent in Cloud Functions was missing knowledge of several board features (borderColor, fontFamily, frame styling, sticky note typography). The AI couldn't fully style objects the way users can manually.
**The Prompt**: Comprehensive plan identifying 8 gaps (tool definitions, execution handlers, ToolInput interface, compactBoardObject, system prompt) with exact line numbers and code changes for each.
**Why It Worked**: Structured gap analysis organized by feature area rather than by file location made it easy to implement all changes systematically. Including both the tool schema changes and the corresponding execution handler changes ensured nothing was missed. Adding a font family mapping helper (FONT_FAMILY_MAP + resolveFontFamily) created a clean abstraction between the user-facing enum values (sans/serif/mono/cursive) and the CSS font-family strings.
**Prior Attempts That Failed**: N/A — plan-first implementation, single file.

## [2026-02-20] — Playful copy overhaul: dopamine-first rewrite
**Category**: feature
**Context**: UI copy was functional but flat. Needed every text touchpoint to emphasize playfulness, using variable reward language, social belonging cues, achievement framing, and sensory language to trigger micro-dopamine hits.
**The Prompt**: Detailed 13-file plan mapping every string change with before/after values, organized by file, with brain science principles applied (variable reward, momentum language, social belonging, achievement framing, anticipation, sensory language, active voice).
**Why It Worked**: Exhaustive before/after mapping left zero ambiguity — each string had exact old and new values with file locations. Explicitly listing files NOT modified (error messages, toolbar labels, shape names) prevented over-application of playfulness where clarity matters more. User feedback refined two buttons (Google login, guest) back to original — playfulness at auth entry points can feel untrustworthy.
**Prior Attempts That Failed**: Initial plan included "Jump in with Google" and "Skip ahead — go anonymous" for auth buttons, which user found too wild for trust-sensitive login context.

## [2026-02-20] — AI Agent improved frame & group embedding
**Category**: feature
**Context**: AI agent had parentId on creation tools and an updateParent tool, but in practice: getBoardSummary didn't show frame children, updateParent didn't reposition objects, templates created hollow frames, and there was no bulk "embed in frame" tool.
**The Prompt**: 5-part plan: (1) enrich getBoardSummary with childCount + frame position, (2) upgrade updateParent to auto-reposition into frame, (3) new embedInFrame convenience tool for bulk moves, (4) populate SWOT/Kanban/Retro/Eisenhower templates with starter stickies, (5) update system prompt with new guidance.
**Why It Worked**: Each change addressed a specific gap in the frame→children workflow. The auto-reposition logic in updateParent and embedInFrame shares the same stacking strategy (find existing children bottom, stack below with 10px gap). Starter stickies in templates teach both users and the AI model the parentId pattern by example.
**Prior Attempts That Failed**: N/A — plan-first implementation, single file.

## [2026-02-20] — Switch AI backend from Anthropic to OpenCode MiniMax M2.5
**Category**: architecture
**Context**: Project used Anthropic Claude Haiku 4.5 via @langchain/anthropic for the AI assistant Cloud Function. Needed to switch to MiniMax M2.5 Free via OpenCode Zen API (OpenAI-compatible).
**The Prompt**: "Switch AI backend from Anthropic Claude to OpenCode MiniMax M2.5 Free" with a detailed plan specifying 4 edits in index.ts (secret, import, model instantiation), package.json swap, and deployment steps.
**Why It Worked**: LangChain's provider abstraction made the swap surgical — only 4 lines of config changed plus package swap. The OpenAI-compatible API meant tool definitions, system prompt, and tool execution loop all stayed identical. Planning identified every reference to the old provider (secret name, secrets array, lazy import, constructor) preventing partial migration.
**Prior Attempts That Failed**: N/A — plan-first implementation.

## [2026-02-20] — Fast/Pro AI mode toggle with <2s Fast mode
**Category**: feature
**Context**: AI assistant took 15-45s per round trip (Firestore trigger + LangChain overhead + double LLM call + observability). Needed <2s response for common operations while keeping full AI power available.
**The Prompt**: Detailed 7-part plan: (A) client-side command parser with regex matching for creates/deletes/templates, (B) Fast/Pro toggle UI in chat header, (C1-C6) Pro mode optimizations — eliminate second LLM call, trim tokens, parallelize tools, remove Langfuse/OTEL, switch to HTTP callable, replace LangChain with direct fetch.
**Why It Worked**: Two-pronged approach: Fast mode bypasses the Cloud Function entirely (client-side parsing + direct Firestore writes = <2s), while Pro mode optimizations attack every layer of latency (HTTP callable eliminates Eventarc trigger, direct fetch eliminates LangChain module loading, single LLM call eliminates the feedback loop, parallel Promise.all for tools, trimmed system prompt for fewer tokens). The auto-fallback from Fast→Pro when commands aren't recognized ensures no loss of capability.
**Prior Attempts That Failed**: N/A — plan-first implementation across 6 files.

## [2026-02-20] — Agent performance: executePlan + template engine + batch writes
**Category**: feature
**Context**: Cloud Function made individual Firebase writes per tool call and exposed 24+ tools, causing slow responses (5-28s for templates, timeouts for complex commands). Needed atomic batch writes, fewer tools for the LLM to parse, and a template engine to bypass the LLM entirely for known patterns.
**The Prompt**: 10-step plan: (1) buildObjectData helper extracting creation logic, (2) executeExecutePlan with tempId resolution + batch write, (3) executePlan tool schema replacing 8 creation tools, (4) template engine (detectTemplate/executeFlowchart/executeTemplate) for SWOT/kanban/retro/eisenhower/mind-map/flowchart, (5-6) tool array + prompt + labels updates, (7) remove maxTokens cap + error handling, (8) sentToBack for frames + batch-ify duplicateObject/embedInFrame.
**Why It Worked**: Three orthogonal optimizations each addressing a different bottleneck: (a) executePlan collapses N Firebase writes into 1 batch.commit(), (b) template engine detects regex patterns before any LLM/LangChain import saving ~3-5s cold start, (c) removing maxTokens:4096 prevents silent truncation causing finish_reason:'length' instead of tool_calls. The tempId→realId resolution map enables cross-referencing in a single tool call.
**Prior Attempts That Failed**: N/A — plan-first implementation, single file.

## [2026-02-20] — CLAUDE.md best practices deep research (round 2)
**Category**: architecture
**Context**: Second round of deep research specifically targeting concrete patterns, real examples, hook configurations, skill structures, and anti-patterns for CLAUDE.md and AI coding assistant project instruction files. Needed actionable blueprints for rewriting the project's CLAUDE.md.
**The Prompt**: "Research the web for specific, detailed CLAUDE.md best practices" with 7 targeted search queries covering GitHub examples, hooks, subagents, Cursor rules, and official Anthropic documentation.
**Why It Worked**: Fetching 15+ full-length articles (Anthropic official docs, HumanLayer, Builder.io, Steve Kinney hook examples, ChrisWiles showcase repo, Shrivu Shankar's feature guide, gold-standard-files pattern) produced concrete JSON configurations, real CLAUDE.md templates, and specific token budget numbers. Key quantitative findings: root CLAUDE.md should be <=150 lines, global <=50 lines, system prompt consumes ~10K tokens before conversation starts, and skills should use lazy-loading to avoid startup bloat.
**Prior Attempts That Failed**: Round 1 research was broad but lacked concrete hook JSON configs, skill YAML frontmatter examples, and specific token budget numbers.

## [2026-02-20] — CLAUDE.md rewrite: progressive disclosure architecture
**Category**: architecture
**Context**: CLAUDE.md was 361 lines — well over the recommended 150-line threshold. Research showed instruction-following accuracy drops with monolithic files. Needed to restructure using progressive disclosure (lean root + on-demand skills).
**The Prompt**: "research best practices for ai-first software engineering, and upgrade our CLAUDE.MD but make a backup first"
**Why It Worked**: Two-phase research (broad + deep) identified 8 anti-patterns in the original file (aspirational rules, file-by-file descriptions, entire workflow tutorials in root). The rewrite applied 4 key patterns: (1) Quick Facts table at top for most-referenced info, (2) Gold Standard Files for concrete pattern references, (3) Gotchas section for non-inferable knowledge, (4) Progressive disclosure via 3 skills for testing/git/docs. Result: 116 lines root (68% reduction) with zero information loss.
**Prior Attempts That Failed**: N/A — research-first approach.
